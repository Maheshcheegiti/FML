{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN7dpP4V3e+SYbKOKLkMSMZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maheshcheegiti/FML/blob/main/Text_Normalization_Stemming.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Text Normalization - Stemming\n",
        "Stemming is a basic way of implementing text normalization in NLP. In this process, we get rid of the inflectional part of the word(prefixes and suffixes) by stripping them off. In other words, we get a stem of the word. Stemming does not consider the semantic meaning of the words while reducing them. This is a major drawback because the root word formed may have lost its semantic meaning. For example, the word \"laziness\" will be reduced to \"lazy\" and not \"lazy\"."
      ],
      "metadata": {
        "id": "7tgw6Hbv2VPn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6n5UmyMzVMq",
        "outputId": "17b64101-efd4-41b7-8fe9-b7b02d3b8ed9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "porter = PorterStemmer()\n",
        "sentence=\"Pythoners are very intelligent and work very pythonly and now they are pythoning their way to success.\""
      ],
      "metadata": {
        "id": "H8i6p3Oi1hSk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stemSentence(sentence):\n",
        "  token_words=word_tokenize(sentence)\n",
        "  print(\"Token Words: \",token_words)\n",
        "  stem_sentence=[]\n",
        "  for word in token_words:\n",
        "    stem_sentence.append(porter.stem(word))\n",
        "    stem_sentence.append(\" \")\n",
        "  return \"\".join(stem_sentence)"
      ],
      "metadata": {
        "id": "Wz9xOKgg1i_N"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=stemSentence(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcSZPaeG1tGV",
        "outputId": "4d68a3f5-eded-45da-d122-932b020fa55e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token Words:  ['Pythoners', 'are', 'very', 'intelligent', 'and', 'work', 'very', 'pythonly', 'and', 'now', 'they', 'are', 'pythoning', 'their', 'way', 'to', 'success', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Senetence after Stemming: \",x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQ9vE0AA2MsU",
        "outputId": "dddd6986-6e68-4b49-c9bf-5dc1f29816a9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Senetence after Stemming:  python are veri intellig and work veri pythonli and now they are python their way to success . \n"
          ]
        }
      ]
    }
  ]
}